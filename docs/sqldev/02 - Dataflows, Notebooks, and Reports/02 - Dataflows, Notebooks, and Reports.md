![](https://raw.githubusercontent.com/microsoft/sqlworkshops/master/graphics/microsoftlogo.png)
# Workshop: SQL database in Microsoft Fabric

## Dataflows, Notebooks, and Reports

#### A Microsoft Workshop from the SQL Server Team

### Dataflows, Notebooks, and Reports

In this module, you'll explore the seamless integration between your SQL database and other artifacts within your Fabric workspace.

You'll cover these topics in this module:

1. [Data Ingestion via Dataflows](https://github.com/akatesmith/SQL-database-in-Fabric-Workshop/blob/main/sqldev/02%20-%20Dataflows%2C%20Notebooks%2C%20and%20Reports/02%20-%20Dataflows%2C%20Notebooks%2C%20and%20Reports.md#21-data-ingestion-via-dataflows)
2. [Exploring Notebooks to Create Views](https://github.com/akatesmith/SQL-database-in-Fabric-Workshop/blob/main/sqldev/02%20-%20Dataflows%2C%20Notebooks%2C%20and%20Reports/02%20-%20Dataflows%2C%20Notebooks%2C%20and%20Reports.md#22-exploring-notebooks-to-create-views)
3. [Generating Reports Using the Integrated Semantic Models and Views](https://github.com/akatesmith/SQL-database-in-Fabric-Workshop/blob/main/sqldev/02%20-%20Dataflows%2C%20Notebooks%2C%20and%20Reports/02%20-%20Dataflows%2C%20Notebooks%2C%20and%20Reports.md#23-create-a-report-over-our-data)

### 2.1 Data Ingestion via Dataflows

You are going to use a data pipeline to ingest the data from `speaker_profiles.csv` into our database. Dataflows allow us to load data from straightforward sources like spreadsheets, .csv files, directly from an alternate database, and more.

#### Activity: Create a Data Flow to Ingest Data

0. Before you begin working in fabric, download the file [`speaker_profiles.csv`](https://github.com/akatesmith/SQL-database-in-Fabric-Workshop/blob/main/sqldev/02%20-%20Dataflows%2C%20Notebooks%2C%20and%20Reports/speaker_profiles.csv) somewhere locally on your machine.
1. From your Fabric workspace, select your SQL database and open it.
2. Click on **Get Data** at the top of the screen, and select **New Dataflow Gen2**. This will open a new data flow.
3. Once the new Data Flow opens, click the **Get Data** button in the ribbon. You can also click the down arrow on **Get Data** and select **more**.
4. From this window, scroll down to the upload file portion (or select upload from the sidebar on the left).
5. Drag and drop [`speaker_profiles.csv`](https://github.com/akatesmith/SQL-database-in-Fabric-Workshop/blob/main/sqldev/02%20-%20Dataflows%2C%20Notebooks%2C%20and%20Reports/speaker_profiles.csv) into the file upload panel. (*Note: this data was generated by AI*)
6. Wait for the file to upload, then click **Next**.
7. Sample data will load. Click **Create**.
8. From here, you may notice that the first row of data includes your column headers.  If this is the case, in the top tab next to **Home**, select **Transform**.  Then, select the icon that says **Use first row as headers**, and this will transform your data so that you not have appropriate column header names.
   At this point, your data should look like you wish it to. You now need to select a data destination.
10. In the bottom right of the screen, click the **+** icon next to **Data destination**, and select **SQL database**.
11. Click **Next**.
12. Make sure that the radio button for **New table** is selected, and that the **Table name** is `speaker_profiles`.
13. In the pane on the left, select your database from the list, or search for it in the search panel. Select that database and click **Next**.
14. Select **Save settings** to use the automatic settings for type detection.
15. Now that you have set a data destination, you can publish your new table. In the bottom right, click **Publish**. This will take you back to the workspace view, and you can see your dataflow working. It will take a few minutes to ingest the data.

### 2.2 Exploring Notebooks to Create Views

Fabric comes with built-in notebooks that can be used to query and interact with the analytical backend for your database. In Fabric, your SQL database is automatically mirrored to an analytics endpoint. This means that you can run your reports off of that, while the front end can serve more online activities.

#### Activity: Create a Notebook and Some Views to Support Reporting

1. From your workspace, select **New item** at the top.
2. Filter the search for **Notebook** and select any of the options that say **Notebook**.
3. Before writing any queries, use the drop-down at the top (between **Connect** and **Environment**) to select **T-SQL** for the environment. You must also select **T-SQL** from the drop-down in the bottom right-hand of the top panel in your editor pane.
4. In the left pane that says **Explorer**, select **Warehouses** and hit **+ Warehouses**.
5. Select the item with the name of your database, and type **SQL Analytics endpoint**, and hit **Confirm**.
6. First, try to query the speaker count by location.

```sql
SELECT Location, COUNT(Location) AS LocationCount
FROM speaker_profiles
GROUP BY Location;
```

Run this query - you can see some data, so you can go ahead and save it as a view.

7. To save as a view, first use your mouse to select the query text you wish to use for the view. Then hover over the icons on the top right of your query cell pane until you find **Save as view**. Select this.
8. Name your view `vSpeakerLocationsByCount` and hit **OK**.
9. Execute another query by clicking the **+Code** button below the results of this one.
10. Paste the following into the box and run it:

```sql
SELECT Name, About
FROM speaker_profiles
WHERE Name IN (
    SELECT full_name
    FROM speakers 
    WHERE id IN (
      SELECT speaker_id
      FROM sessions_speakers
      )
    )
```

9. Save this query as a view as well. Call it `vSpeakersWithSessions`.
10. You can save the notebook for later and rename it to `Sessions Finder Notebook` by selecting the name of the notebook at the top left of the screen.
11. You can now find, select, and continue to edit this file from the Fabric workspace. You can also share this notebook and collaborate.

### 2.3 Create a Report Over Our Data

Now you can automatically leverage the views you created in our notebooks for reporting. You will see how quickly and easily a report can be generated right within Fabric with the data and views already created.

#### Activity: Create a PowerBI Report Over the Views and Data

1. From your workspace, select your analytics endpoint.
2. Once open, select the **Model layouts** from the top ribbon. Scroll until you find **location_breakdown** in this view, and select the **count** field.
3. In the properties pane, scroll to the bottom and expand **Advanced**. For **Summarize by** select **None**.
4. Go ahead and connect various fields as appropriate - drag and drop to create relationships that make sense.
5. Now, above the ribbon next to **Home**, select **Reporting**.
6. Click **New report**, and permit it to import all available tables and data.
7. Create a few charts and visualizations.
8. Now you can save your report by selecting **File > Save** at the top. Once saved, the report can be shared, exported, or edited.

---

Congratulations! You have now imported data using dataflows, explored that data with notebooks, and generated a report over that data!  You are ready to move on to the next module which introduces AI into our solution: [Incorporating Artificial Intelligence](https://github.com/akatesmith/SQL-database-in-Fabric-Workshop/blob/main/sqldev/03%20-%20Incorporating%20Artificial%20Intelligence/03%20-%20Incorporating%20Artificial%20Intelligence.md)

---
